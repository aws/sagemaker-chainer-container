{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting a pre-trained Object Detection model with Chainer\n",
    "\n",
    "In this notebook, we will demonstrate how to host a pre-trained Chainer model on Amazon SageMaker. We'll send images to a model that identifies objects in an image, and draws bounding boxes around those objects.\n",
    "\n",
    "For more on the Chainer container, please visit the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:\n",
    "\n",
    "* https://github.com/aws/sagemaker-chainer-containers\n",
    "* https://github.com/aws/sagemaker-python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# This role retrieves the SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Model Weights\n",
    "\n",
    "We download model weights from a model that has already been trained, create a compressed tarball from it, and upload it to S3. The Chainer container will download and load this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Download the model weights.\n",
    "try:\n",
    "    url = 'https://github.com/yuyu2172/share-weights/releases/download/0.0.3/ssd300_voc0712_2017_06_06.npz'\n",
    "    urllib.request.urlretrieve (url, '/tmp/ssd_model.npz')\n",
    "\n",
    "# Tar and compress the model.\n",
    "    with tarfile.open('/tmp/model.tar.gz', \"w:gz\") as tar:\n",
    "         tar.add('/tmp/ssd_model.npz', arcname='ssd_model.npz')\n",
    "\n",
    "# Upload the model. The `ChainerModel` will use `uploaded_data` to download this model.\n",
    "\n",
    "    uploaded_model = sagemaker_session.upload_data(path='/tmp/model.tar.gz', \n",
    "                                                   key_prefix='notebook/chainercv_ssd')\n",
    "finally:\n",
    "    os.remove('/tmp/ssd_model.npz')\n",
    "    os.remove('/tmp/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the `chainercv_ssd.py` script below on SageMaker. This script contains two functions which are used to load the model and predict with the model.\n",
    "\n",
    "The function hooks for hosting and inference recognized by the container are listed below:\n",
    "\n",
    "\n",
    "### Hosting and Inference\n",
    "\n",
    "* **`model_fn(model_dir)`**: This function is invoked to load model artifacts from those written into `model_dir` during training.\n",
    "* `input_fn(input_data, content_type)`: This function is invoked to deserialize prediction data when a prediction request is made. The return value is passed to predict_fn. `input_fn` accepts two arguments: `input_data`, which is the serialized input data in the body of the prediction request, and `content_type`, the MIME type of the data\n",
    "  \n",
    "  \n",
    "* `predict_fn(input_data, model)`: This function accepts the return value of `input_fn` (as `input_data`) and the return value of `model_fn`, `model`, and returns inferences obtained from the model\n",
    "  \n",
    "  \n",
    "* `output_fn(prediction, accept)`: This function is invoked to serialize the return value from `predict_fn`, passed in via `prediction`, back to the SageMaker client in response to prediction requests\n",
    "\n",
    "\n",
    "This script implements `model_fn`, and `predict_fn`, but relies on the default `input_fn` and `output_fn`.\n",
    "\n",
    "For more on implementing these functions, see the documentation at https://github.com/aws/sagemaker-python-sdk.\n",
    "\n",
    "For more on the functions provided by the Chainer container, see https://github.com/aws/sagemaker-chainer-containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat chainercv_ssd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting the Model\n",
    "\n",
    "We construct an instance of `ChainerModel`, passing in S3 URL to the uploaded model to `model_data` and the script to `entry_point`. We'll host on a single `ml.m4.xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.chainer.model import ChainerModel\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "\n",
    "model = ChainerModel(model_data=uploaded_model, role=role, entry_point='chainercv_ssd.py')\n",
    "\n",
    "endpoint_name = 'chainer-ssd-{}'.format(sagemaker_timestamp())\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1, endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions with the Hosted Model\n",
    "\n",
    "Our pre-trained model is now hosted on SageMaker and loaded in the instance. We can use the `predictor` to obtain predictions from our hosted model.\n",
    "\n",
    "First, let's examine an image that we'd like to detect objects for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainercv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "image = chainercv.utils.read_image('images/dog.jpg', color=True)\n",
    "image = np.ascontiguousarray(image, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.visualizations.vis_image import vis_image\n",
    "vis_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtain predictions. Our model can accept an image (as a NumPy array) and return labels corresponding to objects in the image, scores corresponding to the confidence of those labels, and bounding boxes around those objects.\n",
    "\n",
    "We pass in the image as a numpy array to `predictor.predict`, and `predict_fn` will be invoked with the arrays we send. We retrieve the bounding boxes, labels, and scores the model predicts given the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, label, score = predictor.predict(image)\n",
    "print('bounding box: {}\\nlabel: {}\\nscore: {}'.format(bbox, label, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the bounding boxes predicted by the hosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.visualizations import vis_bbox\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "import matplotlib.pyplot as plt\n",
    "vis_bbox(image, bbox, label, score, label_names=voc_bbox_label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for other images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display_images(image_path):\n",
    "    image = chainercv.utils.read_image(image_path, color=True)\n",
    "    image = np.ascontiguousarray(image, dtype=np.uint8)\n",
    "\n",
    "    vis_image(image)\n",
    "    bbox, label, score = predictor.predict(image)\n",
    "    vis_bbox(image, bbox, label, score, label_names=voc_bbox_label_names)\n",
    "    plt.show()\n",
    "\n",
    "predict_and_display_images('images/dogs.jpg')\n",
    "predict_and_display_images('images/cats.jpg')\n",
    "predict_and_display_images('images/cows.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
   "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific  language governing permissions and limitations under the License."
},
 "nbformat": 4,
 "nbformat_minor": 2
}
