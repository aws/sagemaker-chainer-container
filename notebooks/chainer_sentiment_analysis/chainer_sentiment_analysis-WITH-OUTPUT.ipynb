{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a sentiment analysis model with Chainer\n",
    "\n",
    "In this notebook, we will train a model that will allow us to analyze text for positive or negative sentiment. The model will use a recurrent neural network with long short-term memory blocks to generate word embeddings.\n",
    "\n",
    "To train with a Chainer script, we construct a ```Chainer``` estimator using the [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk). We can pass in an `entry_point`, the name of a script that contains a couple of functions with certain signatures (`train` and `model_fn`). This script will be run on SageMaker in a container that invokes these functions to train and load Chainer models. \n",
    "\n",
    "For more on the Chainer container, please visit the sagemaker-chainer-containers repository:\n",
    "https://github.com/aws/sagemaker-chainer-containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# This role retrieves the SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading training and test data\n",
    "\n",
    "We use helper functions given by `chainer` to download and preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "train, test, vocab = dataset.get_stsa_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data\n",
    "\n",
    "We save the preprocessed data to the local filesystem, and then use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value `inputs` identifies the S3 location, which we will use when we start the Training Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data = [element[0] for element in train]\n",
    "train_labels = [element[1] for element in train] \n",
    "\n",
    "test_data = [element[0] for element in test]\n",
    "test_labels = [element[1] for element in test]\n",
    "\n",
    "try:\n",
    "    os.makedirs('data/train')\n",
    "    os.makedirs('data/test')\n",
    "    os.makedirs('data/vocab')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "np.savez('data/train/train.npz', data=train_data, labels=train_labels)\n",
    "np.savez('data/test/test.npz', data=test_data, labels=test_labels)\n",
    "np.save('data/vocab/vocab.npy', vocab)\n",
    "\n",
    "# Upload preprocessed data to S3 \n",
    "train_input = sagemaker_session.upload_data(path=os.path.join('data', 'train'),\n",
    "                                                            key_prefix='notebook/chainer_sentiment/train')\n",
    "test_input = sagemaker_session.upload_data(path=os.path.join('data', 'test'),\n",
    "                                                           key_prefix='notebook/chainer_sentiment/test')\n",
    "vocab_input = sagemaker_session.upload_data(path=os.path.join('data', 'vocab'),\n",
    "                                                           key_prefix='notebook/chainer_sentiment/vocab')\n",
    "\n",
    "# Remove data from notebook instance (to save disk space)\n",
    "shutil.rmtree('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Chainer training script to run on Amazon SageMaker\n",
    "\n",
    "We need to provide a training script that can run on the SageMaker platform. The training scripts are essentially the same as one you would write for local training, except that you need to provide a function `train` that returns a trained `chainer.Chain`. Since we will use the same script to host the Chainer model, the script also needs a function `model_fn` that loads a `chainer.Chain` -- by default, Chainer models are saved to disk as `model.npz`. When SageMaker calls your `train` and `model_fn` functions, it will pass in arguments that describe the training environment.\n",
    "\n",
    "Check the script below, which uses `chainer` to train on any number of GPUs on a single machine, to see how this works. For more on implementing these functions, see the documentation at https://github.com/aws/sagemaker-python-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\"). You\r\n",
      "# may not use this file except in compliance with the License. A copy of\r\n",
      "# the License is located at\r\n",
      "#\r\n",
      "#     http://aws.amazon.com/apache2.0/\r\n",
      "#\r\n",
      "# or in the \"license\" file accompanying this file. This file is\r\n",
      "# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\r\n",
      "# ANY KIND, either express or implied. See the License for the specific\r\n",
      "# language governing permissions and limitations under the License.\r\n",
      "\r\n",
      "import os\r\n",
      "import json\r\n",
      "\r\n",
      "import numpy as np\r\n",
      "import chainer\r\n",
      "from chainer import training\r\n",
      "from chainer import serializers\r\n",
      "from chainer.training import extensions\r\n",
      "\r\n",
      "import nets\r\n",
      "from nlp_utils import convert_seq, split_text, normalize_text, transform_to_array\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Training methods                                             #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def train(hyperparameters, num_gpus, output_data_dir, channel_input_dirs):\r\n",
      "    \"\"\"\r\n",
      "    This function is called by the Chainer container during training when running on SageMaker with\r\n",
      "    values populated by the training environment.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        hyperparameters (dict): map of hyperparameters given to the training job.\r\n",
      "        num_gpus (int): number of gpus available to the container, determined by instance type.\r\n",
      "        output_data_dir (str): path to the directory to write output artifacts to\r\n",
      "        channel_input_dirs (dict): Dictionary mapping input channel names to local filesystem paths\r\n",
      "\r\n",
      "    Returns:\r\n",
      "        a trained Chainer model\r\n",
      "\r\n",
      "    For more on `train`, please visit the sagemaker-python-sdk repository:\r\n",
      "    https://github.com/aws/sagemaker-python-sdk\r\n",
      "\r\n",
      "    For more on the Chainer container, please visit the sagemaker-chainer-containers repository:\r\n",
      "    https://github.com/aws/sagemaker-chainer-containers\r\n",
      "    \"\"\"\r\n",
      "    train_data = np.load(os.path.join(channel_input_dirs['train'], 'train.npz'))['data']\r\n",
      "    train_labels = np.load(os.path.join(channel_input_dirs['train'], 'train.npz'))['labels']\r\n",
      "\r\n",
      "    test_data = np.load(os.path.join(channel_input_dirs['test'], 'test.npz'))['data']\r\n",
      "    test_labels = np.load(os.path.join(channel_input_dirs['test'], 'test.npz'))['labels']\r\n",
      "\r\n",
      "    vocab = np.load(os.path.join(channel_input_dirs['vocab'], 'vocab.npy')).tolist()\r\n",
      "\r\n",
      "    train = chainer.datasets.TupleDataset(train_data, train_labels)\r\n",
      "    test = chainer.datasets.TupleDataset(test_data, test_labels)\r\n",
      "\r\n",
      "    print('# train data: {}'.format(len(train)))\r\n",
      "    print('# test  data: {}'.format(len(test)))\r\n",
      "    print('# vocab: {}'.format(len(vocab)))\r\n",
      "    num_classes = len(set([int(d[1]) for d in train]))\r\n",
      "    print('# class: {}'.format(num_classes))\r\n",
      "\r\n",
      "    batch_size = hyperparameters.get('batch_size', 64)\r\n",
      "    epochs = hyperparameters.get('epochs', 30)\r\n",
      "    dropout = hyperparameters.get('dropout', 0.4)\r\n",
      "    num_layers = hyperparameters.get('num_layers', 1)\r\n",
      "    num_units = hyperparameters.get('num_units', 300)\r\n",
      "    model_type = hyperparameters.get('model', 'cnn')\r\n",
      "    num_loaders = hyperparameters.get('num_loaders', 1)\r\n",
      "\r\n",
      "    print('# Minibatch-size: {}'.format(batch_size))\r\n",
      "    print('# epoch: {}'.format(epochs))\r\n",
      "    print('# Dropout: {}'.format(dropout))\r\n",
      "    print('# Layers: {}'.format(num_layers))\r\n",
      "    print('# Units: {}'.format(num_units))\r\n",
      "\r\n",
      "    # Setup a model\r\n",
      "    if model_type == 'rnn':\r\n",
      "        Encoder = nets.RNNEncoder\r\n",
      "    elif model_type == 'cnn':\r\n",
      "        Encoder = nets.CNNEncoder\r\n",
      "    elif model_type == 'bow':\r\n",
      "        Encoder = nets.BOWMLPEncoder\r\n",
      "    else:\r\n",
      "        raise ValueError('model_type must be \"rnn\", \"cnn\", or \"bow\"')\r\n",
      "\r\n",
      "    encoder = Encoder(n_layers=num_layers, n_vocab = len(vocab), n_units=num_units, dropout=dropout)\r\n",
      "    model = nets.TextClassifier(encoder, num_classes)\r\n",
      "\r\n",
      "    # Setup an optimizer\r\n",
      "    optimizer = chainer.optimizers.Adam()\r\n",
      "    optimizer.setup(model)\r\n",
      "    optimizer.add_hook(chainer.optimizer.WeightDecay(1e-4))\r\n",
      "\r\n",
      "    # Set up a trainer\r\n",
      "    device = 0 if num_gpus > 0 else -1  # -1 indicates CPU, 0 indicates first GPU device.\r\n",
      "    if num_gpus > 1:\r\n",
      "        devices = range(num_gpus)\r\n",
      "        train_iters = [chainer.iterators.SerialIterator(i, batch_size) \\\r\n",
      "                    for i in chainer.datasets.split_dataset_n_random(train, len(devices))]\r\n",
      "        test_iter = chainer.iterators.SerialIterator(test, batch_size, repeat=False, shuffle=False)\r\n",
      "        updater = training.updaters.MultiprocessParallelUpdater(train_iters, optimizer,\r\n",
      "                                                                converter=convert_seq, devices=range(num_gpus))\r\n",
      "    else:\r\n",
      "        train_iter = chainer.iterators.SerialIterator(train, batch_size)\r\n",
      "        test_iter = chainer.iterators.SerialIterator(test, batch_size, repeat=False, shuffle=False)\r\n",
      "        updater = training.updater.StandardUpdater(train_iter, optimizer, converter=convert_seq, device=device)\r\n",
      "\r\n",
      "    trainer = training.Trainer(updater, (epochs, 'epoch'), out=output_data_dir)\r\n",
      "\r\n",
      "    # Evaluate the model with the test dataset for each epoch\r\n",
      "    trainer.extend(extensions.Evaluator(test_iter, model, converter=convert_seq, device=device))\r\n",
      "\r\n",
      "    # Take a best snapshot.\r\n",
      "    record_trigger = training.triggers.MaxValueTrigger('validation/main/accuracy', (1, 'epoch'))\r\n",
      "    trainer.extend(extensions.snapshot_object(model, 'best_model.npz'), trigger=record_trigger)\r\n",
      "\r\n",
      "    # Write a log of evaluation statistics for each epoch\r\n",
      "    trainer.extend(extensions.LogReport())\r\n",
      "    trainer.extend(extensions.PrintReport(\r\n",
      "        ['epoch', 'main/loss', 'validation/main/loss',\r\n",
      "         'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\r\n",
      "\r\n",
      "    # Print a progress bar to stdout\r\n",
      "    trainer.extend(extensions.ProgressBar())\r\n",
      "\r\n",
      "    if extensions.PlotReport.available():\r\n",
      "        trainer.extend(\r\n",
      "            extensions.PlotReport(['main/loss', 'validation/main/loss'],\r\n",
      "                                  'epoch', file_name='loss.png'))\r\n",
      "        trainer.extend(\r\n",
      "            extensions.PlotReport(\r\n",
      "                ['main/accuracy', 'validation/main/accuracy'],\r\n",
      "                'epoch', file_name='accuracy.png'))\r\n",
      "\r\n",
      "    # Save additional model settings, which will be used to reconstruct the model during hosting\r\n",
      "    model_setup = {}\r\n",
      "    model_setup['num_classes'] = num_classes\r\n",
      "    model_setup['model_type'] = model_type\r\n",
      "    model_setup['num_layers'] = num_layers\r\n",
      "    model_setup['num_units'] = num_units\r\n",
      "    model_setup['dropout'] = dropout\r\n",
      "\r\n",
      "    # Run the training\r\n",
      "    trainer.run()\r\n",
      "\r\n",
      "    # SageMaker saves the return value of train() in the `save` function in the resulting\r\n",
      "    # model artifact model.tar.gz, and the contents of `output_data_dir` in the output\r\n",
      "    # artifact output.tar.gz.\r\n",
      "\r\n",
      "    # load the best model\r\n",
      "    serializers.load_npz(os.path.join(output_data_dir, 'best_model.npz'), model)\r\n",
      "\r\n",
      "    # remove the best model from output artifacts (since it will be saved as a model artifact)\r\n",
      "    os.remove(os.path.join(output_data_dir, 'best_model.npz'))\r\n",
      "    return model, vocab, model_setup\r\n",
      "\r\n",
      "\r\n",
      "def save(model, model_dir):\r\n",
      "    \"\"\"\r\n",
      "    Writes model artifacts to `model_dir`.\r\n",
      "\r\n",
      "    During hosting, `model_fn` will load these artifacts to reconstruct the model for inference.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        model: the return value of `train` -- in this case, a tuple of the trained model,\r\n",
      "               vocab dict, and model_setup dict.\r\n",
      "        model_dir: the directory to save model artifacts to, the contents of which are tarred,\r\n",
      "               zipped, and uploaded to S3.\r\n",
      "\r\n",
      "    For more on `save`, please visit the sagemaker-python-sdk repository:\r\n",
      "    https://github.com/aws/sagemaker-python-sdk\r\n",
      "\r\n",
      "    For more on the Chainer container, please visit the sagemaker-chainer-containers repository:\r\n",
      "    https://github.com/aws/sagemaker-chainer-containers\r\n",
      "    \"\"\"\r\n",
      "    trained_model, vocab, model_setup = model\r\n",
      "\r\n",
      "    serializers.save_npz(os.path.join(model_dir, 'model.npz'), trained_model)\r\n",
      "    with open(os.path.join(model_dir, 'vocab.json'), 'w') as f:\r\n",
      "        json.dump(vocab, f)\r\n",
      "    with open(os.path.join(model_dir, 'args.json'), 'w') as f:\r\n",
      "        json.dump(model_setup, f)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Hosting methods                                              #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    \"\"\"\r\n",
      "    This function is called by the Chainer container during hosting when running on SageMaker with\r\n",
      "    values populated by the hosting environment.\r\n",
      "\r\n",
      "    Above, we defined a function `save(model, model_dir)`, which saves model artifacts during training.\r\n",
      "    This function loads the model artifacts from the model directory during hosting.\r\n",
      "\r\n",
      "    By default, the Chainer container saves models as .npz files, with the name 'model.npz'. In\r\n",
      "    your training script, you can override this behavior by implementing a function with\r\n",
      "    signature `save(model, model_dir)`.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        model_dir (str): path to the directory containing the saved model artifacts\r\n",
      "\r\n",
      "    Returns:\r\n",
      "        a loaded Chainer model\r\n",
      "\r\n",
      "    For more on `model_fn` and `save`, please visit the sagemaker-python-sdk repository:\r\n",
      "    https://github.com/aws/sagemaker-python-sdk\r\n",
      "\r\n",
      "    For more on the Chainer container, please visit the sagemaker-chainer-containers repository:\r\n",
      "    https://github.com/aws/sagemaker-chainer-containers\r\n",
      "    \"\"\"\r\n",
      "    model_path = os.path.join(model_dir, 'model.npz')\r\n",
      "\r\n",
      "    vocab_path = os.path.join(model_dir, 'vocab.json')\r\n",
      "    model_setup_path = os.path.join(model_dir, 'args.json')\r\n",
      "    with open(vocab_path, 'r') as f:\r\n",
      "        vocab = json.load(f)\r\n",
      "    with open(model_setup_path, 'r') as f:\r\n",
      "        model_setup = json.load(f)\r\n",
      "\r\n",
      "    model_type = model_setup['model_type']\r\n",
      "    if model_type == 'rnn':\r\n",
      "        Encoder = nets.RNNEncoder\r\n",
      "    elif model_type == 'cnn':\r\n",
      "        Encoder = nets.CNNEncoder\r\n",
      "    elif model_type == 'bow':\r\n",
      "        Encoder = nets.BOWMLPEncoder\r\n",
      "    num_layers = model_setup['num_layers']\r\n",
      "    num_units = model_setup['num_units']\r\n",
      "    dropout = model_setup['dropout']\r\n",
      "    num_classes = model_setup['num_classes']\r\n",
      "    encoder = Encoder(n_layers=num_layers, n_vocab=len(vocab), n_units=num_units, dropout=dropout)\r\n",
      "    model = nets.TextClassifier(encoder, num_classes)\r\n",
      "\r\n",
      "    serializers.load_npz(model_path, model)\r\n",
      "\r\n",
      "    return model, vocab\r\n",
      "\r\n",
      "\r\n",
      "def predict_fn(input_data, model):\r\n",
      "    \"\"\"\r\n",
      "    This function receives a NumPy array and makes a prediction on it using the model returned\r\n",
      "    by `model_fn`.\r\n",
      "    \r\n",
      "    The default predictor used by `Chainer` serializes input data to the 'npy' format:\r\n",
      "    https://docs.scipy.org/doc/numpy-1.14.0/neps/npy-format.html\r\n",
      "\r\n",
      "    The Chainer container provides an overridable pre-processing function `input_fn`\r\n",
      "    that accepts the serialized input data and deserializes it into a NumPy array.\r\n",
      "    `input_fn` is invoked before `predict_fn` and passes its return value to this function\r\n",
      "    (as `input_data`)\r\n",
      "    \r\n",
      "    The Chainer container provides an overridable post-processing function `output_fn`\r\n",
      "    that accepts this function's return value and serializes it back into `npy` format, which\r\n",
      "    the Chainer predictor can deserialize back into a NumPy array on the client.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        input_data (bytes): a numpy array containing the data serialized by the Chainer predictor\r\n",
      "        model: the return value of `model_fn`\r\n",
      "    Returns:\r\n",
      "        a NumPy array containing predictions which will be returned to the client\r\n",
      "\r\n",
      "\r\n",
      "    For more on `input_fn`, `predict_fn` and `output_fn`, please visit the sagemaker-python-sdk repository:\r\n",
      "    https://github.com/aws/sagemaker-python-sdk\r\n",
      "\r\n",
      "    For more on the Chainer container, please visit the sagemaker-chainer-containers repository:\r\n",
      "    https://github.com/aws/sagemaker-chainer-containers\r\n",
      "    \"\"\"\r\n",
      "    trained_model, vocab = model\r\n",
      "\r\n",
      "    words_batch = []\r\n",
      "    for sentence in input_data.tolist():\r\n",
      "        text = normalize_text(sentence)\r\n",
      "        words = split_text(text)\r\n",
      "        words_batch.append(words)\r\n",
      "\r\n",
      "    xs = transform_to_array(words_batch, vocab, with_label=False)\r\n",
      "    xs = convert_seq(xs, with_label=False)\r\n",
      "\r\n",
      "    with chainer.using_config('train', False), chainer.no_backprop_mode():\r\n",
      "        probs = trained_model.predict(xs, softmax=True)\r\n",
      "    answers = trained_model.xp.argmax(probs, axis=1)\r\n",
      "    scores = probs[trained_model.xp.arange(answers.size), answers].tolist()\r\n",
      "\r\n",
      "    output = []\r\n",
      "    for words, answer, score in zip(words_batch, answers, scores):\r\n",
      "        output.append([' '.join(words), answer, score])\r\n",
      "\r\n",
      "    return np.array(output)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'code/sentiment_analysis.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training script on SageMaker\n",
    "\n",
    "The ```Chainer``` class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on two `ml.p3.2xlarge` instances.\n",
    "\n",
    "This script uses the `chainermn` package, which distributes training with MPI. Your script is run with `mpirun`, so a `chainermn\n",
    "\n",
    "Chainer scripts can distribute training with the `chainermn` package, which this Chainer script does not use, so this script should only be run on one instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-chainer-2018-05-05-00-26-03-431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................\n",
      "\u001b[31m2018-05-05 00:29:37,636 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,636 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,648 INFO - container_support.app - started training: {'train_fn': <function train at 0x7f451ebc7bf8>}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-038453126632/sagemaker-chainer-2018-05-05-00-26-03-431/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,783 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,863 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-west-2-038453126632.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,908 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-us-west-2-038453126632.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,923 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-west-2-038453126632.s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:37,979 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-us-west-2-038453126632.s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:38,035 INFO - chainer_framework.training - Invoking user training script.\u001b[0m\n",
      "\u001b[31m# train data: 6920\u001b[0m\n",
      "\u001b[31m# test  data: 1821\u001b[0m\n",
      "\u001b[31m# vocab: 7142\u001b[0m\n",
      "\u001b[31m# class: 2\u001b[0m\n",
      "\u001b[31m# Minibatch-size: 64\u001b[0m\n",
      "\u001b[31m# epoch: 10\u001b[0m\n",
      "\u001b[31m# Dropout: 0.4\u001b[0m\n",
      "\u001b[31m# Layers: 1\u001b[0m\n",
      "\u001b[31m# Units: 300\u001b[0m\n",
      "\u001b[31mepoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:56,985 INFO - matplotlib.font_manager - font search path ['/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/ttf', '/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/afm', '/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\u001b[0m\n",
      "\u001b[31m2018-05-05 00:29:57,312 INFO - matplotlib.font_manager - generated new fontManager\u001b[0m\n",
      "\u001b[31m#033[J     total [####..............................................]  9.25%\u001b[0m\n",
      "\u001b[31mthis epoch [##############################################....] 92.49%\n",
      "       100 iter, 0 epoch / 10 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J1           0.704831    0.670672              0.526089       0.564599                  21.3009       \u001b[0m\n",
      "\u001b[31m#033[J     total [#########.........................................] 18.50%\u001b[0m\n",
      "\u001b[31mthis epoch [##########################################........] 84.97%\n",
      "       200 iter, 1 epoch / 10 epochs\n",
      "    34.871 iters/sec. Estimated time to finish: 0:00:25.272036.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J2           0.662365    0.606824              0.606337       0.7045                    24.0304       \u001b[0m\n",
      "\u001b[31m#033[J     total [#############.....................................] 27.75%\u001b[0m\n",
      "\u001b[31mthis epoch [######################################............] 77.46%\n",
      "       300 iter, 2 epoch / 10 epochs\n",
      "    36.613 iters/sec. Estimated time to finish: 0:00:21.337887.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J3           0.573889    0.500233              0.702836       0.772183                  26.739        \u001b[0m\n",
      "\u001b[31m#033[J     total [##################................................] 36.99%\u001b[0m\n",
      "\u001b[31mthis epoch [##################################................] 69.94%\n",
      "       400 iter, 3 epoch / 10 epochs\n",
      "    37.321 iters/sec. Estimated time to finish: 0:00:18.253848.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J4           0.435082    0.416632              0.801505       0.807428                  29.4679       \u001b[0m\n",
      "\u001b[31m#033[J     total [#######################...........................] 46.24%\u001b[0m\n",
      "\u001b[31mthis epoch [###############################...................] 62.43%\n",
      "       500 iter, 4 epoch / 10 epochs\n",
      "    37.599 iters/sec. Estimated time to finish: 0:00:15.459257.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J5           0.326682    0.421819              0.858652       0.816049                  32.1586       \u001b[0m\n",
      "\u001b[31m#033[J     total [###########################.......................] 55.49%\u001b[0m\n",
      "\u001b[31mthis epoch [###########################.......................] 54.91%\n",
      "       600 iter, 5 epoch / 10 epochs\n",
      "     37.69 iters/sec. Estimated time to finish: 0:00:12.768706.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J6           0.247185    0.44551               0.900318       0.816587                  34.9012       \u001b[0m\n",
      "\u001b[31m#033[J     total [################################..................] 64.74%\u001b[0m\n",
      "\u001b[31mthis epoch [#######################...........................] 47.40%\n",
      "       700 iter, 6 epoch / 10 epochs\n",
      "    37.925 iters/sec. Estimated time to finish: 0:00:10.052610.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J7           0.177147    0.494279              0.931424       0.808282                  37.6005       \u001b[0m\n",
      "\u001b[31m#033[J     total [####################################..............] 73.99%\u001b[0m\n",
      "\u001b[31mthis epoch [###################...............................] 39.88%\n",
      "       800 iter, 7 epoch / 10 epochs\n",
      "    39.088 iters/sec. Estimated time to finish: 0:00:07.195258.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J8           0.140316    0.581348              0.945602       0.805589                  39.7822       \u001b[0m\n",
      "\u001b[31m#033[J     total [#########################################.........] 83.24%\u001b[0m\n",
      "\u001b[31mthis epoch [################..................................] 32.37%\n",
      "       900 iter, 8 epoch / 10 epochs\n",
      "    40.023 iters/sec. Estimated time to finish: 0:00:04.528635.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J9           0.0980214   0.714089              0.962299       0.801055                  41.9872       \u001b[0m\n",
      "\u001b[31m#033[J     total [##############################################....] 92.49%\u001b[0m\n",
      "\u001b[31mthis epoch [############......................................] 24.86%\n",
      "      1000 iter, 9 epoch / 10 epochs\n",
      "    40.824 iters/sec. Estimated time to finish: 0:00:01.990252.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J10          0.0938061   0.707583              0.962529       0.797618                  44.2005       \u001b[0m\n",
      "\u001b[31m#033[J\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 162\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.chainer.estimator import Chainer\n",
    "\n",
    "chainer_estimator = Chainer(entry_point='sentiment_analysis.py', source_dir=\"code\", role=role,\n",
    "                            sagemaker_session=sagemaker_session,\n",
    "                            train_instance_count=1, train_instance_type='ml.p3.2xlarge',\n",
    "                            hyperparameters={'epochs': 10, 'batch_size': 64})\n",
    "\n",
    "chainer_estimator.fit({'train': train_input, 'test': test_input, 'vocab': vocab_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Chainer script writes various artifacts, such as plots, to a directory `output_data_dir`, the contents of which which SageMaker uploads to S3. Now we download and extract these artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-038453126632/sagemaker-chainer-2018-05-05-00-26-03-431/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from s3_util import retrieve_output_from_s3\n",
    "\n",
    "chainer_training_job = chainer_estimator.latest_training_job.name\n",
    "\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=chainer_training_job)\n",
    "output_data = desc['ModelArtifacts']['S3ModelArtifacts'].replace('model.tar.gz', 'output.tar.gz')\n",
    "\n",
    "retrieve_output_from_s3(output_data, 'output/sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "These plots show the accuracy and loss over epochs.\n",
       "\n",
       "In our user script (sentiment_analysis.py), we save only the best model for deployment.\n",
       "\n",
       "<img style=\"display: inline;\" src=\"output/sentiment/accuracy.png?1525480243.1649876\" />\n",
       "<img style=\"display: inline;\" src=\"output/sentiment/loss.png?1525480243.1649876\" />"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing as code to reload images so that browsers don't render cached images.\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "_nonce = time.time()\n",
    "\n",
    "Markdown(\"\"\"\n",
    "These plots show the accuracy and loss over epochs.\n",
    "\n",
    "In our user script (sentiment_analysis.py), we save only the best model for deployment.\n",
    "\n",
    "<img style=\"display: inline;\" src=\"output/sentiment/accuracy.png?{0}\" />\n",
    "<img style=\"display: inline;\" src=\"output/sentiment/loss.png?{0}\" />\"\"\".format(_nonce))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Trained Model\n",
    "\n",
    "After training, we use the Chainer estimator object to create and deploy a hosted prediction endpoint. We can use a CPU-based instance for inference (in this case an `ml.m4.xlarge`), even though we trained on GPU instances.\n",
    "\n",
    "The predictor object returned by `deploy` lets us call the new endpoint and perform inference on our sample images.\n",
    "\n",
    "At the end of training, `sentiment_analysis.py` saves the trained model, the vocabulary, and a dictionary of model properties that are used to reconstruct the model. These model artifacts are loaded in `model_fn` when the model is hosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-chainer-2018-05-05-00-26-03-431\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-chainer-2018-05-05-00-26-03-431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = chainer_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting using SageMaker Endpoint\n",
    "\n",
    "The Chainer predictor converts its input into a NumPy array, which it serializes and sends to the hosted model.\n",
    "The `predict_fn` in `sentiment_analysis.py` receives this NumPy array and uses the loaded model to make predictions on the input data, which it returns as a NumPy array back to the Chainer predictor.\n",
    "\n",
    "We predict against the hosted model on a batch of sentences. The output, as defined by `predict_fn`, consists of the processed input sentence, the prediction, and the score for that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: it is fun and easy to train chainer models on amazon sagemaker!\n",
      "prediction: 1\n",
      "score: 0.9977222084999084\n",
      "\n",
      "sentence: it used to be slow, difficult, and laborious to train and deploy a model to production.\n",
      "prediction: 0\n",
      "score: 0.8841550946235657\n",
      "\n",
      "sentence: but now it is super fast to deploy to production. and i love it when my model generalizes!\n",
      "prediction: 1\n",
      "score: 0.8739688396453857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = ['It is fun and easy to train Chainer models on Amazon SageMaker!',\n",
    "             'It used to be slow, difficult, and laborious to train and deploy a model to production.',\n",
    "             'But now it is super fast to deploy to production. And I love it when my model generalizes!',]\n",
    "predictions = predictor.predict(sentences)\n",
    "for prediction in predictions:\n",
    "    sentence, prediction, score = prediction\n",
    "    print('sentence: {}\\nprediction: {}\\nscore: {}\\n'.format(sentence, prediction, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-chainer-2018-05-05-00-26-03-431\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
