{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Training and Prediction with SageMaker Chainer\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/), the \"Hello World\" of machine learning, is a popular dataset for handwritten digit classification. It consists of 70,000 28x28 grayscale images labeled in 10 digit classes(0 to 9). This tutorial will show how to train on MNIST using SageMaker Chainer in [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST datasets\n",
    "\n",
    "We can use chainer built-in get_mnist() method to download, import and structure MNIST dataset. It may take several minutes to run this cell for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories already exist!\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "\n",
    "try:\n",
    "    os.makedirs('data/train')\n",
    "    os.makedirs('data/test')\n",
    "except FileExistsError:\n",
    "    print('Directories already exist!')\n",
    "\n",
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse, save, and upload the data\n",
    "\n",
    "Now we split each of training dataset and testing dataset to images and labels. Then it's convenient for us to save training data and testing data to npz files, a format that's popular in chainer world, to local filesystem. Then we can use `sagemaker.Session.upload_data` to upload the data to an S3 location used for training. The return value `inputs` identifies this S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_images = np.array([data[0] for data in train])\n",
    "train_labels = np.array([data[1] for data in train])\n",
    "test_images = np.array([data[0] for data in test])\n",
    "test_labels = np.array([data[1] for data in test])\n",
    "\n",
    "np.savez('data/train/train.npz', images=train_images, labels=train_labels)\n",
    "np.savez('data/test/test.npz', images=test_images, labels=test_labels)\n",
    "\n",
    "train_input = sagemaker_session.upload_data(path=os.path.join('data', 'train'), key_prefix='notebook/chainer/mnist')\n",
    "test_input = sagemaker_session.upload_data(path=os.path.join('data', 'test'), key_prefix='notebook/chainer/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user script for training and prediction\n",
    "\n",
    "We need to provide a user script that can run on the SageMaker platform. The script is essentially the same as one you would write for local training, except that a function `train` that returns a trained `chainer.Chain` model is required. By default, this model is saved to disk as an npz file named `model.npz`.\n",
    "For prediciton, this script also requires a function `model_fn` that loads the `chainer.Chain` saved from training. When SageMaker calls your `train` and `model_fn` functions, it will pass in arguments that describe the training environment.\n",
    "\n",
    "### TODO: Add link to README for user script writing here.\n",
    "\n",
    "The below user script used in our tutorial is adapted from [chainer mnist example](https://github.com/chainer/chainer/blob/master/examples/mnist/train_mnist.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#  \r\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\").\r\n",
      "#  You may not use this file except in compliance with the License.\r\n",
      "#  A copy of the License is located at\r\n",
      "#  \r\n",
      "#      http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#  \r\n",
      "#  or in the \"license\" file accompanying this file. This file is distributed \r\n",
      "#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either \r\n",
      "#  express or implied. See the License for the specific language governing \r\n",
      "#  permissions and limitations under the License.\r\n",
      "\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "import numpy as np\r\n",
      "import chainer\r\n",
      "import chainer.functions as F\r\n",
      "import chainer.links as L\r\n",
      "from chainer import training, serializers\r\n",
      "from chainer.training import extensions\r\n",
      "from chainer.datasets import tuple_dataset\r\n",
      "\r\n",
      "\r\n",
      "# Define the network to train MNIST\r\n",
      "class MLP(chainer.Chain):\r\n",
      "    def __init__(self, n_units, n_out):\r\n",
      "        super(MLP, self).__init__()\r\n",
      "        with self.init_scope():\r\n",
      "            # the size of the inputs to each layer will be inferred\r\n",
      "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\r\n",
      "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\r\n",
      "            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\r\n",
      "\r\n",
      "    def __call__(self, x):\r\n",
      "        h1 = F.relu(self.l1(x))\r\n",
      "        h2 = F.relu(self.l2(h1))\r\n",
      "        return self.l3(h2)\r\n",
      "\r\n",
      "\r\n",
      "# Function to train MNIST. Required.\r\n",
      "def train(channel_input_dirs, hyperparameters, num_gpus, output_data_dir):\r\n",
      "    # Create MNIST dataset objects from files\r\n",
      "    train_images = np.load(os.path.join(channel_input_dirs['train'], 'train.npz'))['images']\r\n",
      "    train_labels = np.load(os.path.join(channel_input_dirs['train'], 'train.npz'))['labels']\r\n",
      "    test_images = np.load(os.path.join(channel_input_dirs['test'], 'test.npz'))['images']\r\n",
      "    test_labels = np.load(os.path.join(channel_input_dirs['test'], 'test.npz'))['labels']\r\n",
      "    \r\n",
      "    train_dataset = chainer.datasets.TupleDataset(train_images, train_labels)\r\n",
      "    test_dataset = chainer.datasets.TupleDataset(test_images, test_labels)\r\n",
      "\r\n",
      "    # Load all hyperparameters\r\n",
      "    batch_size = hyperparameters.get('batch_size', 64)\r\n",
      "    epochs = hyperparameters.get('epochs', 20)\r\n",
      "    frequency = hyperparameters.get('frequency', epochs)\r\n",
      "\r\n",
      "    # Create the network\r\n",
      "    model = L.Classifier(MLP(1000, 10))\r\n",
      "\r\n",
      "    # Configure gpu if necessary\r\n",
      "    if num_gpus > 0:\r\n",
      "        chainer.cuda.get_device_from_id(0).use()\r\n",
      "\r\n",
      "    # Setup an optimizer\r\n",
      "    optimizer = chainer.optimizers.Adam()\r\n",
      "    optimizer.setup(model)\r\n",
      "\r\n",
      "    # Load the MNIST dataset\r\n",
      "    train_iter = chainer.iterators.SerialIterator(train_dataset, batch_size)\r\n",
      "    test_iter = chainer.iterators.SerialIterator(test_dataset, batch_size,\r\n",
      "                                                 repeat=False, shuffle=False)\r\n",
      "\r\n",
      "    # Set up a trainer\r\n",
      "    device = 0 if num_gpus > 0 else -1  # -1 indicates CPU, 0 indicates first GPU device.\r\n",
      "    if num_gpus > 0:\r\n",
      "        updater = training.ParallelUpdater(\r\n",
      "            train_iter,\r\n",
      "            optimizer,\r\n",
      "            # The device of the name 'main' is used as a \"master\", while others are\r\n",
      "            # used as slaves. Names other than 'main' are arbitrary.\r\n",
      "            devices={('main' if device == 0 else str(device)): device for device in range(num_gpus)})\r\n",
      "    else:\r\n",
      "        updater = training.StandardUpdater(train_iter, optimizer, device=device)\r\n",
      "\r\n",
      "    # Write output files to output_data_dir. These are zipped and uploaded to S3 output path as output.tar.gz.\r\n",
      "    trainer = training.Trainer(updater, (epochs, 'epoch'), out=output_data_dir)\r\n",
      "\r\n",
      "    # Evaluate the model with the test dataset for each epoch\r\n",
      "    trainer.extend(extensions.Evaluator(test_iter, model, device=device))\r\n",
      "\r\n",
      "    # Dump a computational graph from 'loss' variable at the first iteration\r\n",
      "    # The \"main\" refers to the target link of the \"main\" optimizer.\r\n",
      "    trainer.extend(extensions.dump_graph('main/loss'))\r\n",
      "\r\n",
      "    # Take a snapshot for each specified epoch\r\n",
      "    trainer.extend(extensions.snapshot(), trigger=(frequency, 'epoch'))\r\n",
      "\r\n",
      "    # Write a log of evaluation statistics for each epoch\r\n",
      "    trainer.extend(extensions.LogReport())\r\n",
      "\r\n",
      "    # Save two plot images to the result dir\r\n",
      "    if extensions.PlotReport.available():\r\n",
      "        trainer.extend(\r\n",
      "            extensions.PlotReport(['main/loss', 'validation/main/loss'],\r\n",
      "                                  'epoch', file_name='loss.png'))\r\n",
      "        trainer.extend(\r\n",
      "            extensions.PlotReport(\r\n",
      "                ['main/accuracy', 'validation/main/accuracy'],\r\n",
      "                'epoch', file_name='accuracy.png'))\r\n",
      "\r\n",
      "    # Print selected entries of the log to stdout\r\n",
      "    # Here \"main\" refers to the target link of the \"main\" optimizer again, and\r\n",
      "    # \"validation\" refers to the default name of the Evaluator extension.\r\n",
      "    # Entries other than 'epoch' are reported by the Classifier link, called by\r\n",
      "    # either the updater or the evaluator.\r\n",
      "    trainer.extend(extensions.PrintReport(\r\n",
      "        ['epoch', 'main/loss', 'validation/main/loss',\r\n",
      "         'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\r\n",
      "\r\n",
      "    # Print a progress bar to stdout\r\n",
      "    trainer.extend(extensions.ProgressBar())\r\n",
      "\r\n",
      "    # Run the training\r\n",
      "    trainer.run()\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "# Function to load model from training. Required.\r\n",
      "def model_fn(model_dir):\r\n",
      "    # This object should be created exactly the same as in training.\r\n",
      "    model = L.Classifier(MLP(1000, 10))\r\n",
      "    serializers.load_npz(os.path.join(model_dir, 'model.npz'), model)\r\n",
      "    return model.predictor\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'chainer_mnist_single_machine.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker chainer estimator\n",
    "\n",
    "To train MNIST, let's construct a `sagemaker.chainer.estimator.Chainer` estimator. A quick explanation for some configurable arguments here:\n",
    "\n",
    "`entry_point`: The user script SageMaker runs for training and prediction.\n",
    "\n",
    "`train_instance_count`: The number of SageMaker instances for training. Since we only do single machine training in this tutorial, it should be 1.\n",
    "\n",
    "`train_instance_type`: The type of SageMaker instances for training. We choose `ml.c5.xlarge` for cpu training. If you want gpu training, you could choose other instance type accordingly. See [Amazon SageMaker ML Instance Types](https://aws.amazon.com/sagemaker/pricing/instance-types/)\n",
    "\n",
    "`hyperparameters`: The hyper-parameters defined in the user script. In this tutorial, `epochs`, `batch_size` and `frequency` can be configured and passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.chainer.estimator import Chainer\n",
    "\n",
    "chainer_estimator = Chainer(entry_point='chainer_mnist_single_machine.py', role=role,\n",
    "                            sagemaker_session=sagemaker_session,\n",
    "                            train_instance_count=1, train_instance_type='ml.c5.xlarge',\n",
    "                            hyperparameters={'epochs': 16, 'batch_size': 128})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on MNIST data in S3\n",
    "\n",
    "After we've constructed our Chainer object, we can fit it using the MNIST data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our user script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-chainer-2018-05-04-15-35-40-399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\n",
      "\u001b[31m2018-05-04 15:38:04,576 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,577 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,579 INFO - container_support.app - started training: {'train_fn': <function train at 0x7f750b8f41e0>}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-360423169059/sagemaker-chainer-2018-05-04-15-35-40-399/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,715 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,780 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-west-2-360423169059.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,839 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-us-west-2-360423169059.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,873 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-west-2-360423169059.s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:04,933 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): sagemaker-us-west-2-360423169059.s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:05,033 INFO - chainer_framework.training - Invoking user training script.\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:05,578 INFO - matplotlib.font_manager - font search path ['/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/ttf', '/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/afm', '/usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\u001b[0m\n",
      "\u001b[31m2018-05-04 15:38:05,851 INFO - matplotlib.font_manager - generated new fontManager\u001b[0m\n",
      "\u001b[31mepoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\u001b[0m\n",
      "\u001b[31m#033[J     total [..................................................]  1.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##########........................................] 21.33%\n",
      "       100 iter, 0 epoch / 16 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#.................................................]  2.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#####################.............................] 42.67%\n",
      "       200 iter, 0 epoch / 16 epochs\n",
      "    33.377 iters/sec. Estimated time to finish: 0:03:38.712564.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##................................................]  4.00%\u001b[0m\n",
      "\u001b[31mthis epoch [################################..................] 64.00%\n",
      "       300 iter, 0 epoch / 16 epochs\n",
      "    33.315 iters/sec. Estimated time to finish: 0:03:36.116927.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##................................................]  5.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##########################################........] 85.33%\n",
      "       400 iter, 0 epoch / 16 epochs\n",
      "    33.336 iters/sec. Estimated time to finish: 0:03:32.982051.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J1           0.19853     0.104772              0.939349       0.966179                  15.151        \u001b[0m\n",
      "\u001b[31m#033[J     total [###...............................................]  6.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###...............................................]  6.67%\n",
      "       500 iter, 1 epoch / 16 epochs\n",
      "     30.98 iters/sec. Estimated time to finish: 0:03:45.954629.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####..............................................]  8.00%\u001b[0m\n",
      "\u001b[31mthis epoch [##############....................................] 28.00%\n",
      "       600 iter, 1 epoch / 16 epochs\n",
      "    31.512 iters/sec. Estimated time to finish: 0:03:38.967072.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####..............................................]  9.33%\u001b[0m\n",
      "\u001b[31mthis epoch [########################..........................] 49.33%\n",
      "       700 iter, 1 epoch / 16 epochs\n",
      "    31.695 iters/sec. Estimated time to finish: 0:03:34.541803.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#####.............................................] 10.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###################################...............] 70.67%\n",
      "       800 iter, 1 epoch / 16 epochs\n",
      "    31.529 iters/sec. Estimated time to finish: 0:03:32.502531.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [######............................................] 12.00%\u001b[0m\n",
      "\u001b[31mthis epoch [##############################################....] 92.00%\n",
      "       900 iter, 1 epoch / 16 epochs\n",
      "    31.459 iters/sec. Estimated time to finish: 0:03:29.793700.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J2           0.0720402   0.07856               0.977762       0.97498                   30.7299       \u001b[0m\n",
      "\u001b[31m#033[J     total [######............................................] 13.33%\u001b[0m\n",
      "\u001b[31mthis epoch [######............................................] 13.33%\n",
      "      1000 iter, 2 epoch / 16 epochs\n",
      "     30.43 iters/sec. Estimated time to finish: 0:03:33.602132.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#######...........................................] 14.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#################.................................] 34.67%\n",
      "      1100 iter, 2 epoch / 16 epochs\n",
      "    30.396 iters/sec. Estimated time to finish: 0:03:30.554451.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [########..........................................] 16.00%\u001b[0m\n",
      "\u001b[31mthis epoch [############################......................] 56.00%\n",
      "      1200 iter, 2 epoch / 16 epochs\n",
      "    30.323 iters/sec. Estimated time to finish: 0:03:27.765099.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [########..........................................] 17.33%\u001b[0m\n",
      "\u001b[31mthis epoch [######################################............] 77.33%\n",
      "      1300 iter, 2 epoch / 16 epochs\n",
      "    30.312 iters/sec. Estimated time to finish: 0:03:24.542187.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#########.........................................] 18.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#################################################.] 98.67%\n",
      "      1400 iter, 2 epoch / 16 epochs\n",
      "    30.307 iters/sec. Estimated time to finish: 0:03:21.274899.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J3           0.0472381   0.0707081             0.984725       0.977551                  47.2137       \u001b[0m\n",
      "\u001b[31m#033[J     total [##########........................................] 20.00%\u001b[0m\n",
      "\u001b[31mthis epoch [##########........................................] 20.00%\n",
      "      1500 iter, 3 epoch / 16 epochs\n",
      "    29.732 iters/sec. Estimated time to finish: 0:03:21.801719.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##########........................................] 21.33%\u001b[0m\n",
      "\u001b[31mthis epoch [####################..............................] 41.33%\n",
      "      1600 iter, 3 epoch / 16 epochs\n",
      "    29.772 iters/sec. Estimated time to finish: 0:03:18.170495.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [###########.......................................] 22.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###############################...................] 62.67%\n",
      "      1700 iter, 3 epoch / 16 epochs\n",
      "    29.803 iters/sec. Estimated time to finish: 0:03:14.614067.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [############......................................] 24.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#########################################.........] 84.00%\n",
      "      1800 iter, 3 epoch / 16 epochs\n",
      "    29.822 iters/sec. Estimated time to finish: 0:03:11.134765.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J4           0.0347585   0.0729337             0.988732       0.979628                  63.5915       \u001b[0m\n",
      "\u001b[31m#033[J     total [############......................................] 25.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##................................................]  5.33%\n",
      "      1900 iter, 4 epoch / 16 epochs\n",
      "     29.39 iters/sec. Estimated time to finish: 0:03:10.541790.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#############.....................................] 26.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#############.....................................] 26.67%\n",
      "      2000 iter, 4 epoch / 16 epochs\n",
      "    29.425 iters/sec. Estimated time to finish: 0:03:06.915877.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############....................................] 28.00%\u001b[0m\n",
      "\u001b[31mthis epoch [########################..........................] 48.00%\n",
      "      2100 iter, 4 epoch / 16 epochs\n",
      "    29.448 iters/sec. Estimated time to finish: 0:03:03.372955.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############....................................] 29.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##################################................] 69.33%\n",
      "      2200 iter, 4 epoch / 16 epochs\n",
      "    29.459 iters/sec. Estimated time to finish: 0:02:59.908770.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [###############...................................] 30.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#############################################.....] 90.67%\n",
      "      2300 iter, 4 epoch / 16 epochs\n",
      "    29.475 iters/sec. Estimated time to finish: 0:02:56.418801.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J5           0.0285915   0.0759122             0.990788       0.977947                  80.1686       \u001b[0m\n",
      "\u001b[31m#033[J     total [################..................................] 32.00%\u001b[0m\n",
      "\u001b[31mthis epoch [######............................................] 12.00%\n",
      "      2400 iter, 5 epoch / 16 epochs\n",
      "    29.175 iters/sec. Estimated time to finish: 0:02:54.809554.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [################..................................] 33.33%\u001b[0m\n",
      "\u001b[31mthis epoch [################..................................] 33.33%\n",
      "      2500 iter, 5 epoch / 16 epochs\n",
      "    29.202 iters/sec. Estimated time to finish: 0:02:51.219955.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#################.................................] 34.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###########################.......................] 54.67%\n",
      "      2600 iter, 5 epoch / 16 epochs\n",
      "    29.234 iters/sec. Estimated time to finish: 0:02:47.611232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m#033[4A#033[J     total [##################................................] 36.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#####################################.............] 76.00%\n",
      "      2700 iter, 5 epoch / 16 epochs\n",
      "    29.263 iters/sec. Estimated time to finish: 0:02:44.027371.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##################................................] 37.33%\u001b[0m\n",
      "\u001b[31mthis epoch [################################################..] 97.33%\n",
      "      2800 iter, 5 epoch / 16 epochs\n",
      "    29.268 iters/sec. Estimated time to finish: 0:02:40.587677.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J6           0.0200362   0.0783661             0.993503       0.978441                  96.7539       \u001b[0m\n",
      "\u001b[31m#033[J     total [###################...............................] 38.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#########.........................................] 18.67%\n",
      "      2900 iter, 6 epoch / 16 epochs\n",
      "        29 iters/sec. Estimated time to finish: 0:02:38.621622.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####################..............................] 40.00%\u001b[0m\n",
      "\u001b[31mthis epoch [####################..............................] 40.00%\n",
      "      3000 iter, 6 epoch / 16 epochs\n",
      "    29.004 iters/sec. Estimated time to finish: 0:02:35.153215.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####################..............................] 41.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##############################....................] 61.33%\n",
      "      3100 iter, 6 epoch / 16 epochs\n",
      "    28.996 iters/sec. Estimated time to finish: 0:02:31.747118.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#####################.............................] 42.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#########################################.........] 82.67%\n",
      "      3200 iter, 6 epoch / 16 epochs\n",
      "    28.989 iters/sec. Estimated time to finish: 0:02:28.331525.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J7           0.0198031   0.0768507             0.993787       0.980518                  113.844       \u001b[0m\n",
      "\u001b[31m#033[J     total [######################............................] 44.00%\u001b[0m\n",
      "\u001b[31mthis epoch [##................................................]  4.00%\n",
      "      3300 iter, 7 epoch / 16 epochs\n",
      "    28.749 iters/sec. Estimated time to finish: 0:02:26.090180.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [######################............................] 45.33%\u001b[0m\n",
      "\u001b[31mthis epoch [############......................................] 25.33%\n",
      "      3400 iter, 7 epoch / 16 epochs\n",
      "    28.772 iters/sec. Estimated time to finish: 0:02:22.499635.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#######################...........................] 46.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#######################...........................] 46.67%\n",
      "      3500 iter, 7 epoch / 16 epochs\n",
      "    28.786 iters/sec. Estimated time to finish: 0:02:18.957882.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [########################..........................] 48.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#################################.................] 68.00%\n",
      "      3600 iter, 7 epoch / 16 epochs\n",
      "    28.789 iters/sec. Estimated time to finish: 0:02:15.466533.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [########################..........................] 49.33%\u001b[0m\n",
      "\u001b[31mthis epoch [############################################......] 89.33%\n",
      "      3700 iter, 7 epoch / 16 epochs\n",
      "    28.788 iters/sec. Estimated time to finish: 0:02:11.997154.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J8           0.0163568   0.0810186             0.994558       0.981705                  130.831       \u001b[0m\n",
      "\u001b[31m#033[J     total [#########################.........................] 50.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#####.............................................] 10.67%\n",
      "      3800 iter, 8 epoch / 16 epochs\n",
      "    28.601 iters/sec. Estimated time to finish: 0:02:09.365535.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##########################........................] 52.00%\u001b[0m\n",
      "\u001b[31mthis epoch [################..................................] 32.00%\n",
      "      3900 iter, 8 epoch / 16 epochs\n",
      "    28.609 iters/sec. Estimated time to finish: 0:02:05.833417.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##########################........................] 53.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##########################........................] 53.33%\n",
      "      4000 iter, 8 epoch / 16 epochs\n",
      "    28.614 iters/sec. Estimated time to finish: 0:02:02.317975.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [###########################.......................] 54.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#####################################.............] 74.67%\n",
      "      4100 iter, 8 epoch / 16 epochs\n",
      "    28.618 iters/sec. Estimated time to finish: 0:01:58.804687.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [############################......................] 56.00%\u001b[0m\n",
      "\u001b[31mthis epoch [################################################..] 96.00%\n",
      "      4200 iter, 8 epoch / 16 epochs\n",
      "     28.62 iters/sec. Estimated time to finish: 0:01:55.303768.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J9           0.0182076   0.0728108             0.993853       0.983584                  147.959       \u001b[0m\n",
      "\u001b[31m#033[J     total [############################......................] 57.33%\u001b[0m\n",
      "\u001b[31mthis epoch [########..........................................] 17.33%\n",
      "      4300 iter, 9 epoch / 16 epochs\n",
      "    28.462 iters/sec. Estimated time to finish: 0:01:52.432518.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#############################.....................] 58.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###################...............................] 38.67%\n",
      "      4400 iter, 9 epoch / 16 epochs\n",
      "    28.465 iters/sec. Estimated time to finish: 0:01:48.906765.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############################....................] 60.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#############################.....................] 60.00%\n",
      "      4500 iter, 9 epoch / 16 epochs\n",
      "    28.467 iters/sec. Estimated time to finish: 0:01:45.384650.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############################....................] 61.33%\u001b[0m\n",
      "\u001b[31mthis epoch [########################################..........] 81.33%\n",
      "      4600 iter, 9 epoch / 16 epochs\n",
      "     28.47 iters/sec. Estimated time to finish: 0:01:41.861434.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J10          0.0148335   0.103898              0.994686       0.975376                  165.175       \u001b[0m\n",
      "\u001b[31m#033[J     total [###############################...................] 62.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#.................................................]  2.67%\n",
      "      4700 iter, 10 epoch / 16 epochs\n",
      "    28.325 iters/sec. Estimated time to finish: 0:01:38.853534.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [################################..................] 64.00%\u001b[0m\n",
      "\u001b[31mthis epoch [############......................................] 24.00%\n",
      "      4800 iter, 10 epoch / 16 epochs\n",
      "    28.336 iters/sec. Estimated time to finish: 0:01:35.286437.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [################################..................] 65.33%\u001b[0m\n",
      "\u001b[31mthis epoch [######################............................] 45.33%\n",
      "      4900 iter, 10 epoch / 16 epochs\n",
      "    28.335 iters/sec. Estimated time to finish: 0:01:31.758331.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#################################.................] 66.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#################################.................] 66.67%\n",
      "      5000 iter, 10 epoch / 16 epochs\n",
      "    28.341 iters/sec. Estimated time to finish: 0:01:28.211417.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##################################................] 68.00%\u001b[0m\n",
      "\u001b[31mthis epoch [############################################......] 88.00%\n",
      "      5100 iter, 10 epoch / 16 epochs\n",
      "    28.341 iters/sec. Estimated time to finish: 0:01:24.682692.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J11          0.0111287   0.094989              0.996535       0.980815                  182.473       \u001b[0m\n",
      "\u001b[31m#033[J     total [##################################................] 69.33%\u001b[0m\n",
      "\u001b[31mthis epoch [####..............................................]  9.33%\n",
      "      5200 iter, 11 epoch / 16 epochs\n",
      "    28.206 iters/sec. Estimated time to finish: 0:01:21.543275.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [###################################...............] 70.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###############...................................] 30.67%\n",
      "      5300 iter, 11 epoch / 16 epochs\n",
      "    28.196 iters/sec. Estimated time to finish: 0:01:18.025677.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####################################..............] 72.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#########################.........................] 52.00%\n",
      "      5400 iter, 11 epoch / 16 epochs\n",
      "    28.178 iters/sec. Estimated time to finish: 0:01:14.525590.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [####################################..............] 73.33%\u001b[0m\n",
      "\u001b[31mthis epoch [####################################..............] 73.33%\n",
      "      5500 iter, 11 epoch / 16 epochs\n",
      "    28.171 iters/sec. Estimated time to finish: 0:01:10.995672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m#033[4A#033[J     total [#####################################.............] 74.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###############################################...] 94.67%\n",
      "      5600 iter, 11 epoch / 16 epochs\n",
      "    28.161 iters/sec. Estimated time to finish: 0:01:07.468898.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J12          0.0157669   0.0893426             0.994909       0.979826                  200.228       \u001b[0m\n",
      "\u001b[31m#033[J     total [######################################............] 76.00%\u001b[0m\n",
      "\u001b[31mthis epoch [########..........................................] 16.00%\n",
      "      5700 iter, 12 epoch / 16 epochs\n",
      "    28.032 iters/sec. Estimated time to finish: 0:01:04.212103.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [######################################............] 77.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##################................................] 37.33%\n",
      "      5800 iter, 12 epoch / 16 epochs\n",
      "    28.022 iters/sec. Estimated time to finish: 0:01:00.666571.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#######################################...........] 78.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#############################.....................] 58.67%\n",
      "      5900 iter, 12 epoch / 16 epochs\n",
      "    28.011 iters/sec. Estimated time to finish: 0:00:57.119890.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [########################################..........] 80.00%\u001b[0m\n",
      "\u001b[31mthis epoch [########################################..........] 80.00%\n",
      "      6000 iter, 12 epoch / 16 epochs\n",
      "    27.998 iters/sec. Estimated time to finish: 0:00:53.576203.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J13          0.00876554  0.0829739             0.997285       0.984573                  218.229       \u001b[0m\n",
      "\u001b[31m#033[J     total [########################################..........] 81.33%\u001b[0m\n",
      "\u001b[31mthis epoch [..................................................]  1.33%\n",
      "      6100 iter, 13 epoch / 16 epochs\n",
      "    27.874 iters/sec. Estimated time to finish: 0:00:50.226111.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#########################################.........] 82.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###########.......................................] 22.67%\n",
      "      6200 iter, 13 epoch / 16 epochs\n",
      "    27.868 iters/sec. Estimated time to finish: 0:00:46.649211.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##########################################........] 84.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#####################.............................] 44.00%\n",
      "      6300 iter, 13 epoch / 16 epochs\n",
      "    27.847 iters/sec. Estimated time to finish: 0:00:43.092750.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##########################################........] 85.33%\u001b[0m\n",
      "\u001b[31mthis epoch [################################..................] 65.33%\n",
      "      6400 iter, 13 epoch / 16 epochs\n",
      "    27.828 iters/sec. Estimated time to finish: 0:00:39.528831.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [###########################################.......] 86.67%\u001b[0m\n",
      "\u001b[31mthis epoch [###########################################.......] 86.67%\n",
      "      6500 iter, 13 epoch / 16 epochs\n",
      "    27.814 iters/sec. Estimated time to finish: 0:00:35.952561.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J14          0.00770894  0.0927101             0.997601       0.981705                  236.461       \u001b[0m\n",
      "\u001b[31m#033[J     total [############################################......] 88.00%\u001b[0m\n",
      "\u001b[31mthis epoch [####..............................................]  8.00%\n",
      "      6600 iter, 14 epoch / 16 epochs\n",
      "    27.702 iters/sec. Estimated time to finish: 0:00:32.488090.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [############################################......] 89.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##############....................................] 29.33%\n",
      "      6700 iter, 14 epoch / 16 epochs\n",
      "    27.694 iters/sec. Estimated time to finish: 0:00:28.886833.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#############################################.....] 90.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#########################.........................] 50.67%\n",
      "      6800 iter, 14 epoch / 16 epochs\n",
      "    27.689 iters/sec. Estimated time to finish: 0:00:25.280346.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############################################....] 92.00%\u001b[0m\n",
      "\u001b[31mthis epoch [####################################..............] 72.00%\n",
      "      6900 iter, 14 epoch / 16 epochs\n",
      "    27.681 iters/sec. Estimated time to finish: 0:00:21.675838.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [##############################################....] 93.33%\u001b[0m\n",
      "\u001b[31mthis epoch [##############################################....] 93.33%\n",
      "      7000 iter, 14 epoch / 16 epochs\n",
      "    27.674 iters/sec. Estimated time to finish: 0:00:18.067312.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J15          0.0145037   0.0867281             0.995652       0.981013                  254.527       \u001b[0m\n",
      "\u001b[31m#033[J     total [###############################################...] 94.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#######...........................................] 14.67%\n",
      "      7100 iter, 15 epoch / 16 epochs\n",
      "    27.576 iters/sec. Estimated time to finish: 0:00:14.505550.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [################################################..] 96.00%\u001b[0m\n",
      "\u001b[31mthis epoch [#################.................................] 36.00%\n",
      "      7200 iter, 15 epoch / 16 epochs\n",
      "    27.556 iters/sec. Estimated time to finish: 0:00:10.886862.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [################################################..] 97.33%\u001b[0m\n",
      "\u001b[31mthis epoch [############################......................] 57.33%\n",
      "      7300 iter, 15 epoch / 16 epochs\n",
      "    27.532 iters/sec. Estimated time to finish: 0:00:07.264295.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J     total [#################################################.] 98.67%\u001b[0m\n",
      "\u001b[31mthis epoch [#######################################...........] 78.67%\n",
      "      7400 iter, 15 epoch / 16 epochs\n",
      "    27.504 iters/sec. Estimated time to finish: 0:00:03.635865.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J16          0.0078698   0.0945746             0.997479       0.98121                   273.34        \u001b[0m\n",
      "\u001b[31m#033[J     total [##################################################] 100.00%\u001b[0m\n",
      "\u001b[31mthis epoch [..................................................]  0.00%\n",
      "      7500 iter, 16 epoch / 16 epochs\n",
      "    27.389 iters/sec. Estimated time to finish: 0:00:00.\u001b[0m\n",
      "\u001b[31m#033[4A#033[J\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 361\n"
     ]
    }
   ],
   "source": [
    "chainer_estimator.fit({'train': train_input, 'test': test_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to endpoint\n",
    "\n",
    "After training, we deploy the model to an endpoint using the Chainer estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-chainer-2018-05-04-15-35-40-399\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-chainer-2018-05-04-15-35-40-399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = chainer_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Hand-Written Digit\n",
    "\n",
    "We can now use this predictor to classify hand-written digits. Drawing into the image box loads the pixel data into a variable named 'data' in this notebook, which we can then pass to the Chainer predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">\n",
       "    var pixels = [];\n",
       "    for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    var click = 0;\n",
       "\n",
       "    var canvas = document.querySelector(\"canvas\");\n",
       "    canvas.addEventListener(\"mousemove\", function(e){\n",
       "        if (e.buttons == 1) {\n",
       "            click = 1;\n",
       "            canvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
       "            canvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
       "            x = Math.floor(e.offsetY * 0.2);\n",
       "            y = Math.floor(e.offsetX * 0.2) + 1;\n",
       "            for (var dy = 0; dy < 2; dy++){\n",
       "                for (var dx = 0; dx < 2; dx++){\n",
       "                    if ((x + dx < 28) && (y + dy < 28)){\n",
       "                        pixels[(y+dy)+(x+dx)*28] = 1;\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "        } else {\n",
       "            if (click == 1) set_value();\n",
       "            click = 0;\n",
       "        }\n",
       "    });\n",
       "    function clear_value(){\n",
       "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
       "        canvas.getContext(\"2d\").fillRect(0, 0, 140, 140);\n",
       "        for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    }\n",
       "    \n",
       "    function set_value(){\n",
       "        var result = \"[[\"\n",
       "        for (var i = 0; i < 28; i++) {\n",
       "            for (var j = 0; j < 28; j++) {\n",
       "                result += pixels [i * 28 + j]\n",
       "                if (j < 27) {\n",
       "                    result += \", \"\n",
       "                }\n",
       "            }\n",
       "            if (i < 27) {\n",
       "                result += \", \"\n",
       "            }\n",
       "        }\n",
       "        result += \"]]\"\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute(\"data = \" + result)\n",
       "    }\n",
       "</script>\n",
       "<table>\n",
       "<td style=\"border-style: none;\">\n",
       "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
       "<canvas width=\"140\" height=\"140\"></canvas>\n",
       "</div></td>\n",
       "<td style=\"border-style: none;\">\n",
       "<button onclick=\"clear_value()\">Clear</button>\n",
       "</td>\n",
       "</table>\n",
       "\n",
       "<!-- This work has been modified from the original and is licensed under the Apache 2.0 License. -->\n",
       "\n",
       "<!--\n",
       "                                     Apache License\n",
       "                           Version 2.0, January 2004\n",
       "                        http://www.apache.org/licenses/\n",
       "\n",
       "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
       "\n",
       "   1. Definitions.\n",
       "\n",
       "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
       "      and distribution as defined by Sections 1 through 9 of this document.\n",
       "\n",
       "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
       "      the copyright owner that is granting the License.\n",
       "\n",
       "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
       "      other entities that control, are controlled by, or are under common\n",
       "      control with that entity. For the purposes of this definition,\n",
       "      \"control\" means (i) the power, direct or indirect, to cause the\n",
       "      direction or management of such entity, whether by contract or\n",
       "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
       "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
       "\n",
       "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
       "      exercising permissions granted by this License.\n",
       "\n",
       "      \"Source\" form shall mean the preferred form for making modifications,\n",
       "      including but not limited to software source code, documentation\n",
       "      source, and configuration files.\n",
       "\n",
       "      \"Object\" form shall mean any form resulting from mechanical\n",
       "      transformation or translation of a Source form, including but\n",
       "      not limited to compiled object code, generated documentation,\n",
       "      and conversions to other media types.\n",
       "\n",
       "      \"Work\" shall mean the work of authorship, whether in Source or\n",
       "      Object form, made available under the License, as indicated by a\n",
       "      copyright notice that is included in or attached to the work\n",
       "      (an example is provided in the Appendix below).\n",
       "\n",
       "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
       "      form, that is based on (or derived from) the Work and for which the\n",
       "      editorial revisions, annotations, elaborations, or other modifications\n",
       "      represent, as a whole, an original work of authorship. For the purposes\n",
       "      of this License, Derivative Works shall not include works that remain\n",
       "      separable from, or merely link (or bind by name) to the interfaces of,\n",
       "      the Work and Derivative Works thereof.\n",
       "\n",
       "      \"Contribution\" shall mean any work of authorship, including\n",
       "      the original version of the Work and any modifications or additions\n",
       "      to that Work or Derivative Works thereof, that is intentionally\n",
       "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
       "      or by an individual or Legal Entity authorized to submit on behalf of\n",
       "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
       "      means any form of electronic, verbal, or written communication sent\n",
       "      to the Licensor or its representatives, including but not limited to\n",
       "      communication on electronic mailing lists, source code control systems,\n",
       "      and issue tracking systems that are managed by, or on behalf of, the\n",
       "      Licensor for the purpose of discussing and improving the Work, but\n",
       "      excluding communication that is conspicuously marked or otherwise\n",
       "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
       "\n",
       "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
       "      on behalf of whom a Contribution has been received by Licensor and\n",
       "      subsequently incorporated within the Work.\n",
       "\n",
       "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      copyright license to reproduce, prepare Derivative Works of,\n",
       "      publicly display, publicly perform, sublicense, and distribute the\n",
       "      Work and such Derivative Works in Source or Object form.\n",
       "\n",
       "   3. Grant of Patent License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      (except as stated in this section) patent license to make, have made,\n",
       "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
       "      where such license applies only to those patent claims licensable\n",
       "      by such Contributor that are necessarily infringed by their\n",
       "      Contribution(s) alone or by combination of their Contribution(s)\n",
       "      with the Work to which such Contribution(s) was submitted. If You\n",
       "      institute patent litigation against any entity (including a\n",
       "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
       "      or a Contribution incorporated within the Work constitutes direct\n",
       "      or contributory patent infringement, then any patent licenses\n",
       "      granted to You under this License for that Work shall terminate\n",
       "      as of the date such litigation is filed.\n",
       "\n",
       "   4. Redistribution. You may reproduce and distribute copies of the\n",
       "      Work or Derivative Works thereof in any medium, with or without\n",
       "      modifications, and in Source or Object form, provided that You\n",
       "      meet the following conditions:\n",
       "\n",
       "      (a) You must give any other recipients of the Work or\n",
       "          Derivative Works a copy of this License; and\n",
       "\n",
       "      (b) You must cause any modified files to carry prominent notices\n",
       "          stating that You changed the files; and\n",
       "\n",
       "      (c) You must retain, in the Source form of any Derivative Works\n",
       "          that You distribute, all copyright, patent, trademark, and\n",
       "          attribution notices from the Source form of the Work,\n",
       "          excluding those notices that do not pertain to any part of\n",
       "          the Derivative Works; and\n",
       "\n",
       "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
       "          distribution, then any Derivative Works that You distribute must\n",
       "          include a readable copy of the attribution notices contained\n",
       "          within such NOTICE file, excluding those notices that do not\n",
       "          pertain to any part of the Derivative Works, in at least one\n",
       "          of the following places: within a NOTICE text file distributed\n",
       "          as part of the Derivative Works; within the Source form or\n",
       "          documentation, if provided along with the Derivative Works; or,\n",
       "          within a display generated by the Derivative Works, if and\n",
       "          wherever such third-party notices normally appear. The contents\n",
       "          of the NOTICE file are for informational purposes only and\n",
       "          do not modify the License. You may add Your own attribution\n",
       "          notices within Derivative Works that You distribute, alongside\n",
       "          or as an addendum to the NOTICE text from the Work, provided\n",
       "          that such additional attribution notices cannot be construed\n",
       "          as modifying the License.\n",
       "\n",
       "      You may add Your own copyright statement to Your modifications and\n",
       "      may provide additional or different license terms and conditions\n",
       "      for use, reproduction, or distribution of Your modifications, or\n",
       "      for any such Derivative Works as a whole, provided Your use,\n",
       "      reproduction, and distribution of the Work otherwise complies with\n",
       "      the conditions stated in this License.\n",
       "\n",
       "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
       "      any Contribution intentionally submitted for inclusion in the Work\n",
       "      by You to the Licensor shall be under the terms and conditions of\n",
       "      this License, without any additional terms or conditions.\n",
       "      Notwithstanding the above, nothing herein shall supersede or modify\n",
       "      the terms of any separate license agreement you may have executed\n",
       "      with Licensor regarding such Contributions.\n",
       "\n",
       "   6. Trademarks. This License does not grant permission to use the trade\n",
       "      names, trademarks, service marks, or product names of the Licensor,\n",
       "      except as required for reasonable and customary use in describing the\n",
       "      origin of the Work and reproducing the content of the NOTICE file.\n",
       "\n",
       "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
       "      agreed to in writing, Licensor provides the Work (and each\n",
       "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
       "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
       "      implied, including, without limitation, any warranties or conditions\n",
       "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
       "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
       "      appropriateness of using or redistributing the Work and assume any\n",
       "      risks associated with Your exercise of permissions under this License.\n",
       "\n",
       "   8. Limitation of Liability. In no event and under no legal theory,\n",
       "      whether in tort (including negligence), contract, or otherwise,\n",
       "      unless required by applicable law (such as deliberate and grossly\n",
       "      negligent acts) or agreed to in writing, shall any Contributor be\n",
       "      liable to You for damages, including any direct, indirect, special,\n",
       "      incidental, or consequential damages of any character arising as a\n",
       "      result of this License or out of the use or inability to use the\n",
       "      Work (including but not limited to damages for loss of goodwill,\n",
       "      work stoppage, computer failure or malfunction, or any and all\n",
       "      other commercial damages or losses), even if such Contributor\n",
       "      has been advised of the possibility of such damages.\n",
       "\n",
       "   9. Accepting Warranty or Additional Liability. While redistributing\n",
       "      the Work or Derivative Works thereof, You may choose to offer,\n",
       "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
       "      or other liability obligations and/or rights consistent with this\n",
       "      License. However, in accepting such obligations, You may act only\n",
       "      on Your own behalf and on Your sole responsibility, not on behalf\n",
       "      of any other Contributor, and only if You agree to indemnify,\n",
       "      defend, and hold each Contributor harmless for any liability\n",
       "      incurred by, or claims asserted against, such Contributor by reason\n",
       "      of your accepting any such warranty or additional liability.\n",
       "\n",
       "   END OF TERMS AND CONDITIONS\n",
       "\n",
       "   APPENDIX: How to apply the Apache License to your work.\n",
       "\n",
       "      To apply the Apache License to your work, attach the following\n",
       "      boilerplate notice, with the fields enclosed by brackets \"{}\"\n",
       "      replaced with your own identifying information. (Don't include\n",
       "      the brackets!)  The text should be enclosed in the appropriate\n",
       "      comment syntax for the file format. We also recommend that a\n",
       "      file or class name and description of purpose be included on the\n",
       "      same \"printed page\" as the copyright notice for easier\n",
       "      identification within third-party archives.\n",
       "\n",
       "   Copyright {yyyy} {name of copyright owner}\n",
       "\n",
       "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "   you may not use this file except in compliance with the License.\n",
       "   You may obtain a copy of the License at\n",
       "\n",
       "       http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "   Unless required by applicable law or agreed to in writing, software\n",
       "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "   See the License for the specific language governing permissions and\n",
       "   limitations under the License.\n",
       "-->\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if your writing can be recognized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What you wrote is: 7\n"
     ]
    }
   ],
   "source": [
    "image = np.array(data, dtype=np.float32)\n",
    "prediction = predictor.predict(image)\n",
    "predicted_label = prediction.argmax(axis=1)[0]\n",
    "print('What you wrote is: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get some random test images in MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4895a4f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(test_images.shape[0] - 1), num_samples)\n",
    "images, labels = test_images[indices], test_labels[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can make correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted labels are: [6 2 5 7 3]\n"
     ]
    }
   ],
   "source": [
    "prediction = predictor.predict(images)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('The predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
